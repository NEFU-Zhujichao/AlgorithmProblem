# Redis面经
> String、Hash、List、Set、ZSet、HyperLogLogs、Geospatial、BitMaps、Pub/Sub、**BloomFilter**   
> Redis采用的是基于内存的采用的是单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的QPS（Query Per Second 每秒内查询次数）。
### 缓存穿透 缓存击穿 缓存雪崩
- 缓存穿透：假设这样一个场景，我们数据库中的主键是自增的，然后黑客利用大量肉鸡模拟主键为**负数**的请求，也就是模拟数据库中没有的请求。所以这些请求都会使得数据库进行一次查询，大量请求可能会把数据库直接打崩。
  #### 解决方案：
  - 我会在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id <=0的直接拦截等。
  - set空值：没查到的数据为key 值为null。但是大量的请求会导致redis数据库中存在大量的空值数据。如果说redis内存set满了，redis会进行缓存淘汰策略，导致你redis中老的值或者正在用的值被淘汰掉。一直请求redis，redis服务器的压力也不小。
  - 布隆过滤器：把数据库的部分数据在布隆过滤器中也设置一份。**布隆过滤器能够判断值一定不在里面，但是不能判断值一定在里面**。
- 缓存击穿：假设这样一个场景，一个秒杀系统中的**key**为库存量，如果库存的key突然失效了，所有的请求就都会打到MySQL中，布隆过滤器就没用了因为数据库中都有这些信息，数据库就挡不住大量的请求，容易挂掉。一般都是因为key的失效时间到了或者redis服务器挂了。 
  #### 解决方案：    
    - 不设置key的失效时间。
    - 加上分布式锁。
- 缓存雪崩：举个简单的例子：如果所有首页的Key失效时间都是12小时，中午12点刷新的，我零点有个秒杀活动大量用户涌入，假设当时每秒 6000 个请求，本来缓存在可以扛住每秒 5000 个请求，但是缓存当时所有的Key都失效了。此时 1 秒 6000 个请求全部落数据库，数据库必然扛不住，它会报一下警，真实情况可能DBA都没反应过来就直接挂了。此时，如果没用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。这就是我理解的缓存雪崩。
  #### 解决方案：
    - 处理缓存雪崩简单，在批量往Redis存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效 setRedis(Key,value,time + Math.random() * 10000);
> - 在事故前：Redis的高可用，主从+哨兵 做redis的集群，防止redis服务器挂掉。
> - 在事故中：可能会换成第三方的缓存，本地Ehcache Hystrix限流和降级 避免MySQL被请求打死。
> - 在事故后：假如redis服务器挂了，需要持久化的rdb+aof 服务器一旦重启将会自动从磁盘上加载数据，快速恢复缓存的数据。
### Redis为什么最开始被设计成单线程的？然后又推出了多线程版本？
Redis作为一个成熟的分布式缓存框架，它由很多个模块组成，如网络请求模块、索引模块、存储模块、高可用集群支撑模块、数据操作模块等。  
我们所说的Redis单线程，指的是"其网络IO和键值对读写是由一个线程完成的"，也就是说，Redis中只有网络请求模块和数据操作模块是单线程的。而其他的如持久化存储模块、集群支撑模块等是多线程的。  
那么，为什么网络操作模块和数据存储模块最初并没有使用多线程呢？  
**多线程的目的，就是通过并发的方式来提升I/O的利用率和CPU的利用率。**  
首先，我们可以肯定的说，Redis不需要提升CPU利用率，因为Redis的操作基本都是基于内存的，CPU资源根本就不是Redis的性能瓶颈。  
Redis确实是一个I/O操作密集的框架，他的数据操作过程中，会有大量的网络I/O和磁盘I/O的发生。要想提升Redis的性能，是一定要提升Redis的I/O利用率的，这一点毋庸置疑。但是，提升I/O利用率，并不是只有采用多线程技术这一条路可以走！  
小结：
1. Redis 操作基于内存，绝大多数操作的性能瓶颈不在 CPU
2. 使用单线程模型，可维护性更高，开发，调试和维护的成本更低
3. 单线程模型，避免了线程间切换带来的性能开销
4. 在单线程中使用多路复用 I/O技术也能提升Redis的I/O利用率
### Redis多路复用
Redis 6.0中的多线程，也只是针对处理网络请求过程采用了多线程，而数据的读写命令，仍然是单线程处理的。  
限制Redis的性能的主要瓶颈出现在网络IO的处理上，虽然之前采用了多路复用技术。但是我们前面也提到过，多路复用的IO模型本质上仍然是**同步阻塞型IO模型。**    
![](https://mmbiz.qpic.cn/mmbiz_jpg/6fuT3emWI5Jdhnbn0SIYAKmmRkT7fSLoMedAlc0ljMOibKibFQWRFbLpE3zhklwoj3jm2G0zPw6NDjSTUQOxJic6g/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)  
**从上图我们可以看到，在多路复用的IO模型中，在处理网络请求时，调用 select （其他函数同理）的过程是阻塞的，也就是说这个过程会阻塞线程，如果并发量很高，此处可能会成为瓶颈。**  
**如果能采用多线程，使得网络处理的请求并发进行，就可以大大的提升性能。多线程除了可以减少由于网络 I/O 等待造成的影响，还可以充分利用 CPU 的多核优势。**  
所以，Redis 6.0采用多个IO线程来处理网络请求，网络请求的解析可以由其他线程完成，然后把解析后的请求交由主线程进行实际的内存读写。提升网络请求处理的并行度，进而提升整体性能。但是，Redis 的多 IO 线程只是用来处理网络请求的，对于读写命令，Redis 仍然使用单线程来处理。Redis 6.0 只有在网络请求的接收和解析，以及请求后的数据通过网络返回给时，使用了多线程。而数据读写操作还是由单线程来完成的，所以，这样就不会出现并发问题了。
### 秒杀系统需要注意的问题 Redis如何解决超卖
> 秒杀系统需要注意的问题

1. 高并发
2. 超卖
3. 恶意请求
4. 链接暴露：我知道url了，那我通过程序不断获取最新的北京时间，可以达到毫秒级别的，我就在00毫秒的时候请求，我敢说绝对比你人工点的成功率大太多了，而且我可以一毫秒发送N次请求，搞不好你卖100个产品我全拿了。
   1. 秒杀链接加盐：把URL动态化，就连写代码的人都不知道，你就通过MD5之类的加密算法加密随机的字符串去做url，然后通过前端代码获取url后台校验才能通过。
5. 数据库QPS
> 解决思路：

1. 服务单一职责：
   1. 设计个能抗住高并发的系统，我觉得还是得单一职责。现在设计都是微服务的设计思想，然后再用分布式的部署方式。给秒杀设计一个单独的服务，秒杀代码业务逻辑放在一起。单独建立数据库，至于表就看大家怎么设计了，该设置索引的地方还是要设置索引的，建完后记得用explain看看SQL的执行计划。
   2. 单一职责的好处就是就算秒杀没抗住，秒杀库崩了，服务挂了，也不会影响到其他的服务。（强行高可用）
2. **将判断库存数量操作然后再扣减库存的操作全部放在一个lua脚本中，保证指令的原子性。**
3. Nginx作为高性能的web服务器，并发也随便顶几万不是梦，但是我们的Tomcat只能顶几百的并发呀，那简单呀负载均衡嘛，一台服务几百，那就多搞点，在秒杀的时候多租点流量机。恶意请求拦截也需要用到它，一般单个用户请求次数太夸张，不像人为的请求在网关那一层就得拦截掉了，不然请求多了他抢不抢得到是一回事，服务器压力上去了，可能占用网络带宽或者把服务器打崩、缓存击穿等等。
4. 资源静态化：秒杀一般都是特定的商品还有页面模板，现在一般都是前后端分离的，所以页面一般都是不会经过后端的，但是前端也要自己的服务器啊，那就把能提前放入cdn服务器的东西都放进去，反正把所有能提升效率的步骤都做一下，减少真正秒杀时候服务器的压力。
5. 按钮控制：大家有没有发现没到秒杀前，一般按钮都是置灰的，只有时间到了，才能点击。按钮可以点击之后也得给他置灰几秒，不然他一样在开始之后一直点的。
6. 库存预热：**秒杀的本质，就是对库存的抢夺。** 我们要开始秒杀前你通过定时任务或者运维同学提前把商品的库存加载到Redis中去，让整个流程都在Redis里面去做，然后等秒杀结束了，再异步的去修改库存就好了。
7. 限流&降级&熔断&隔离：这个为啥要做呢，不怕一万就怕万一，万一你真的顶不住了，限流，顶不住就挡一部分出去但是不能说不行，降级，降级了还是被打挂了，熔断，至少不要影响别的系统，隔离，你本身就独立的，但是你会调用其他的系统嘛，你快不行了你别拖累兄弟们啊。
8. 削峰填谷：当秒杀数量很大时，可以把秒杀请求放到MQ，一点一点去消费就好了。
![](https://mmbiz.qpic.cn/mmbiz_png/uChmeeX1FpwWonxxyNO4ibGpUZTVdpQXcAm1xLfv38BKET1ic2SgIhWPUtRXEnuztzoPIRn1KRGIicaY9gicHP0m2g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)
### Redis如何设置分布式锁
先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。**可以同时把setnx和expire合成一条指令来用的！保证指令的原子性。**  
为了防止redis的锁被别人释放，通常会将value设置为uuid或者线程id等这种唯一标识的值，来保证自己的锁是自己释放的。  
当释放锁时，先会判断锁是不是自己的，然后去释放锁。因为这两个操作不是原子性的，所以这个过程在多线程情况下可能会出问题。**所以通常会将这两个命令写到lua脚本中执行，这样能够保证指令的原子性。**
### 使用过Redis做异步队列么，你是怎么用的？
- 一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。
  - 可不可以不用sleep呢：list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来。
- 能不能生产一次消费多次呢：使用pub/sub主题订阅者模式，可以实现 1:N 的消息队列。
  - pub/sub有什么缺点：在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如RocketMQ等。
### Redis是怎么持久化的
- RDB做镜像全量持久化，AOF做增量持久化。因为RDB会耗费较长时间，不够实时，在停机的时候会导致大量数据丢失，所以需要AOF来配合使用。在redis实例重启时，会使用RDB持久化文件重新构建内存，再使用AOF重放近期的操作指令来实现完整恢复重启之前的状态。
  - 如果突然机器掉电会怎样：取决于AOF日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。
> RDB的原理是什么？

fork和COW。fork是指redis通过创建子进程来进行RDB操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。
### Redis的同步机制
Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将RDB文件全量同步到复制节点，复制节点接受完成后将RDB镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。后续的增量数据通过AOF日志同步即可，有点类似数据库的binlog。
### 是否使用过Redis集群，集群的高可用怎么保证，集群的原理是什么？
- Redis Sentinal 着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。
- Redis Cluster 着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。
- 哨兵必须用三个实例去保证自己的健壮性的，哨兵+主从并不能保证数据不丢失，但是可以保证集群的高可用。
- 哨兵组件的主要功能：
  - 集群监控：负责监控 Redis master 和 slave 进程是否正常工作。
  - 消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
  - 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。
  - 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。
### Redis的内存淘汰机制
> Redis的过期策略，是有定期删除+惰性删除两种。 
> - 定期好理解，默认100ms就随机抽一些设置了过期时间的key，去检查是否过期，过期了就删了。
> - 惰性删除，见名知意，惰性嘛，我不主动删，我懒，我等你来查询了我看看你过期没，过期就删了还不给你返回，没过期该怎么样就怎么样。
---
> 内存淘汰机制
> - noeviction:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）
> - allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。
> - volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。
> - allkeys-random: 回收随机的键使得新添加的数据有空间存放。
> - volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。
> - volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。
> - 如果没有键满足回收的前提条件的话，策略volatile-lru, volatile-random以及volatile-ttl就和noeviction 差不多了。
### Bloom Filter 概念
布隆过滤器（英语：Bloom Filter）是1970年由一个叫布隆的小伙子提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。**它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。**  
**面试关联：一般都会在回答缓存穿透，或者海量数据去重这个时候引出来** 
#### Bloom Filter 原理
- 布隆过滤器的原理是，当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。
- Bloom Filter跟单哈希函数Bit-Map不同之处在于：Bloom Filter使用了k个哈希函数，每个字符串跟k个bit对应。从而降低了冲突的概率。
![](https://camo.githubusercontent.com/631552ea28dd438bdc3466dc1ac5f72491b29b1af5678a8ba347d8f1810e5567/68747470733a2f2f696d61676573323031382e636e626c6f67732e636f6d2f626c6f672f3734303539312f3230313830362f3734303539312d32303138303632333138333034353538362d3639323637333837352e6a7067)
#### Bloom Filter的缺点
bloom filter之所以能做到在时间和空间上的效率比较高，是因为牺牲了判断的准确率、删除的便利性  
- 存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。如果bloom filter中存储的是黑名单，那么可以通过建立一个白名单来存储可能会误判的元素。
- 删除困难。一个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断。可以采用Counting Bloom Filter

