# Redis面经
> String、Hash、List、Set、ZSet、HyperLogLog、Geo、BitMap、Pub/Sub、**BloomFilter** 
> Redis采用的是基于内存的采用的是单线程模型的 KV 数据库，由C语言编写，官方提供的数据是可以达到100000+的QPS（每秒内查询次数）。
### 缓存击穿？缓存穿透？缓存雪崩
- 缓存穿透：假设这样一个场景，我们数据库中的主键是自增的，然后黑客利用大量肉鸡模拟主键为**负数**的请求，所以这些请求都会使得数据库进行一次查询，大量请求可能会把数据库直接打崩。
  #### 解决方案：
  - 我会在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id <=0的直接拦截等。
  - set空值：没查到的数据为key 值为null。但是大量的请求会导致redis数据库中存在大量的空值数据。如果说redis内存set满了，redis会进行缓存淘汰策略，导致你redis中老的值或者正在用的值被淘汰掉。一直请求redis，redis服务器的压力也不小。
  - 布隆过滤器：把数据库的部分数据在布隆过滤器中也设置一份。**布隆过滤器能够判断值一定不在里面，但是不能判断值一定在里面**。
- 缓存击穿：假设这样一个场景，一个秒杀系统中的**key**为库存量，如果库存的key突然失效了，所有的请求就都会打到MySQL中，布隆过滤器就没用了因为数据库中都有这些信息，数据库就挡不住大量的请求，容易挂掉。一般都是因为key的失效时间到了或者redis服务器挂了。 
  #### 解决方案：    
    - 不设置key的失效时间。
    - 加上分布式锁。
- 缓存雪崩：举个简单的例子：如果所有首页的Key失效时间都是12小时，中午12点刷新的，我零点有个秒杀活动大量用户涌入，假设当时每秒 6000 个请求，本来缓存在可以扛住每秒 5000 个请求，但是缓存当时所有的Key都失效了。此时 1 秒 6000 个请求全部落数据库，数据库必然扛不住，它会报一下警，真实情况可能DBA都没反应过来就直接挂了。此时，如果没用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。这就是我理解的缓存雪崩。
  #### 解决方案：
    - 处理缓存雪崩简单，在批量往Redis存数据的时候，把每个Key的失效时间都加个随机值就好了，这样可以保证数据不会在同一时间大面积失效
    - setRedis(Key,value,time + Math.random() * 10000);
> - 在事故前：Redis的高可用，主从+哨兵 做redis的集群，防止redis服务器挂掉。
> - 在事故中：可能会换成第三方的缓存，本地Ehcache Hystrix限流和降级 避免MySQL被请求打死。
> - 在事故后：假如redis服务器挂了，需要持久化的rdb+aof 服务器一旦重启将会自动从磁盘上加载数据，快速恢复缓存的数据。
### Redis如何设置分布式锁
> 先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。**可以同时把setnx和expire合成一条指令来用的！**
### 使用过Redis做异步队列么，你是怎么用的？
- 一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。
  - 可不可以不用sleep呢：list还有个指令叫blpop，在没有消息的时候，它会阻塞住直到消息到来。
- 能不能生产一次消费多次呢：使用pub/sub主题订阅者模式，可以实现 1:N 的消息队列。
  - pub/sub有什么缺点：在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如RocketMQ等。
### Redis是怎么持久化的
- RDB做镜像全量持久化，AOF做增量持久化。因为RDB会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要AOF来配合使用。在redis实例重启时，会使用RDB持久化文件重新构建内存，再使用AOF重放近期的操作指令来实现完整恢复重启之前的状态。
  - 如果突然机器掉电会怎样：取决于AOF日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。
> RDB的原理是什么？
- fork和cow。fork是指redis通过创建子进程来进行RDB操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。
### Redis的同步机制
- Redis可以使用主从同步，从从同步。第一次同步时，主节点做一次bgsave，并同时将后续修改操作记录到内存buffer，待完成后将RDB文件全量同步到复制节点，复制节点接受完成后将RDB镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。后续的增量数据通过AOF日志同步即可，有点类似数据库的binlog。
### 是否使用过Redis集群，集群的高可用怎么保证，集群的原理是什么？
- Redis Sentinal 着眼于高可用，在master宕机时会自动将slave提升为master，继续提供服务。
- Redis Cluster 着眼于扩展性，在单个redis内存不足时，使用Cluster进行分片存储。
- 哨兵必须用三个实例去保证自己的健壮性的，哨兵+主从并不能保证数据不丢失，但是可以保证集群的高可用。
- 哨兵组件的主要功能：
  - 集群监控：负责监控 Redis master 和 slave 进程是否正常工作。
  - 消息通知：如果某个 Redis 实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
  - 故障转移：如果 master node 挂掉了，会自动转移到 slave node 上。
  - 配置中心：如果故障转移发生了，通知 client 客户端新的 master 地址。
### Redis的内存淘汰机制
> Redis的过期策略，是有定期删除+惰性删除两种。 
> - 定期好理解，默认100ms就随机抽一些设置了过期时间的key，去检查是否过期，过期了就删了。
> - 惰性删除，见名知意，惰性嘛，我不主动删，我懒，我等你来查询了我看看你过期没，过期就删了还不给你返回，没过期该怎么样就怎么样。
---
> 内存淘汰机制
> - noeviction:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）
> - allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。
> - volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。
> - allkeys-random: 回收随机的键使得新添加的数据有空间存放。
> - volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。
> - volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。
> - 如果没有键满足回收的前提条件的话，策略volatile-lru, volatile-random以及volatile-ttl就和noeviction 差不多了。
### Bloom Filter 概念
布隆过滤器（英语：Bloom Filter）是1970年由一个叫布隆的小伙子提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。**它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。**  
**面试关联：一般都会在回答缓存穿透，或者海量数据去重这个时候引出来** 
#### Bloom Filter 原理
- 布隆过滤器的原理是，当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。
- Bloom Filter跟单哈希函数Bit-Map不同之处在于：Bloom Filter使用了k个哈希函数，每个字符串跟k个bit对应。从而降低了冲突的概率。
![](https://camo.githubusercontent.com/631552ea28dd438bdc3466dc1ac5f72491b29b1af5678a8ba347d8f1810e5567/68747470733a2f2f696d61676573323031382e636e626c6f67732e636f6d2f626c6f672f3734303539312f3230313830362f3734303539312d32303138303632333138333034353538362d3639323637333837352e6a7067)
#### Bloom Filter的缺点
bloom filter之所以能做到在时间和空间上的效率比较高，是因为牺牲了判断的准确率、删除的便利性  
- 存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。如果bloom filter中存储的是黑名单，那么可以通过建立一个白名单来存储可能会误判的元素。
- 删除困难。一个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断。可以采用Counting Bloom Filter

